{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "44b98d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cvxpy as cp\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "from pandas.io.pytables import performance_doc\n",
    "\n",
    "\n",
    "class MyClassifier_25:  \n",
    "\n",
    "    def __init__(self,dataset,class1:int,class2:int,algo=2) -> None:\n",
    "    \n",
    "    # ~~~~~~~~~~~~~~~~~~ VARIABLES THAT SHOULD NOT BE CHANGED ~~~~~~~~~~~~~~~~~~~~~~\n",
    "        self.w = None\n",
    "        self.b = None\n",
    "        self.w_hist = None\n",
    "        self.b_hist = None\n",
    "        self.classes = { 1 : class1, -1: class2, 0:None}\n",
    "        self.dataset_train = dataset\n",
    "\n",
    "        #data prep\n",
    "        self.trainlabel,self.traindata = self.prepare_binary(self.dataset_train)\n",
    "        self.yet_to_train_dataset = self.dataset_train\n",
    "        self.sampled_dataset = None\n",
    "        \n",
    "        self.i = 0 # Dataset Iterator \n",
    "        self.sel_arr = np.zeros(self.traindata.shape[0]) # Binary Array indicating whether a sample -\n",
    "                     # is selected or not in order of sample selection and not dataset index\n",
    "    \n",
    "    # ~~~~~~~~~~~~~~~~~~~~~~~~~ VARIABLES YOU CAN CHANGE ~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "        \n",
    "        # End Iteration\n",
    "        self.iter_end = 1500 # Set it very high if you want to execute over entire dataset\n",
    "        \n",
    "        # Debug Mode - Executes print statements if true\n",
    "        self.debug_mode = False\n",
    "        \n",
    "        # Algorithms:\n",
    "        # 1.Percentage Random Batch Sampling\n",
    "        # 2.Epsilon Greedy Sampling\n",
    "        self.aglo_sel = algo #Set to 2 by default\n",
    "        \n",
    "        # Percentage Random Batch Sampling Variables:\n",
    "        self.perct_sel_smpls = 0.3 # percentage of Selected samples from dataset DEFAULT VALUE\n",
    "        self.batch_size = 100 # Batch Size for samples\n",
    "        self.mini_batch_size = 20 # Mini Batch Size for samples\n",
    "        self.mini_batch_slots_to_be_filled = int(self.perct_sel_smpls * self.mini_batch_size)\n",
    "        self.batch_slots_to_be_filled = int(self.perct_sel_smpls * self.batch_size)\n",
    "        \n",
    "        # Epsilon Greedy Sampling Variables:\n",
    "        self.initial_sample_size = self.batch_size\n",
    "        self.epsilon_out = 0.4\n",
    "        self.epsilon_sv = 0.7\n",
    "    \n",
    "    # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ FUNCTION ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "        # Classifier Function\n",
    "        self.selection_and_train()\n",
    "    \n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~ FUNCTIONS IN ORDER OF EXECUTION ~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "    def selection_and_train(self,select_samples_percent=0.5):\n",
    "        # OPTIONS\n",
    "        # 1. Over entire dataset via some percentage sampling\n",
    "        # 2. Until value converges then switch to rejecting more than accepting and stop taking big batches\n",
    "\n",
    "        self.i = 0 # Dataset Iterator \n",
    "        self.sample_counter = 0\n",
    "        self.mini_batch_slots_to_be_filled = int(select_samples_percent * self.mini_batch_size)\n",
    "        self.batch_slots_to_be_filled = int(select_samples_percent * self.batch_size)\n",
    "        \n",
    "        # Iterate over dataset until it is exhausted (or converged then switch state)\n",
    "        while(self.i<self.sel_arr.size-1):\n",
    "        \n",
    "            # Sample and remove the sample from the dataset (to avoid duplicates in future sampling)\n",
    "            sample = self.yet_to_train_dataset.sample(n=1)\n",
    "            self.yet_to_train_dataset.drop(sample.index)\n",
    "            \n",
    "            # Perform next steps if sample selection is true\n",
    "            if self.sample_selection(sample) is True:\n",
    "                print(\"Sample is accepted\") if self.debug_mode is True else None\n",
    "                self.sample_counter +=1\n",
    "                if self.sampled_dataset is None:\n",
    "                    self.sampled_dataset = sample\n",
    "                else:\n",
    "                    self.sampled_dataset = self.sampled_dataset.append(sample, ignore_index=True)\n",
    "                #print(\"tail:\",self.sampled_dataset.tail)\n",
    "                #print(\"shape:\",self.sampled_dataset.shape)\n",
    "                self.sel_arr[self.i] = 1 # mark as sampled\n",
    "                \n",
    "                # Train Sample if batch size is reached\n",
    "                if (self.sample_counter % self.batch_size) == 0 and (self.sample_counter != 0):\n",
    "                    lbl, dt = self.prepare_binary(self.sampled_dataset)\n",
    "                    self.train(dt,lbl)\n",
    "                    self.store_w_b()\n",
    "            \n",
    "            self.i+=1\n",
    "            if self.i>self.iter_end:\n",
    "                break\n",
    "        lbl, dt = self.prepare_binary(self.sampled_dataset)\n",
    "        self.train(dt,lbl)\n",
    "        \n",
    "    def sample_selection(self,training_sample):\n",
    "        # This method accepts only 1 random training sample at a time and decides whether to send it or not\n",
    "        # Returns True if sample is accepted and False otherwise\n",
    "        # return True if accept_sample == 1 else False\n",
    "        \n",
    "        # INITIALIZE RANDOM SAMPLING=======================================\n",
    "        accept_sample = random.randint(0, 1)\n",
    "        \n",
    "        \n",
    "        # ALGORITHM\n",
    "        # TYPES OF SAMPLING================================================\n",
    "        if self.aglo_sel == 1:\n",
    "            accept_sample = self.mini_batch_sampling()\n",
    "        elif self.aglo_sel == 2:\n",
    "            accept_sample = self.scheduler_sampling(training_sample)\n",
    "        else:\n",
    "            accept_sample = random.randint(0, 1)\n",
    "        \n",
    "        if(self.i==0):\n",
    "            accept_sample = random.randint(0, 1)\n",
    "        \n",
    "        # print(\"accept_sample: \",accept_sample)\n",
    "        print(\"~~~~~~~~~~~~~~~~~~~~~~~~\") if self.debug_mode is True else None\n",
    "        print(\"# \",self.i) if self.debug_mode is True else None\n",
    "        print(\"Inside Sample Selection,\") if self.debug_mode is True else None\n",
    "        print(\"Number of accepted samples: \",self.sample_counter,\" current accepted: \",accept_sample) if self.debug_mode is True else None\n",
    "        # Returns True if sample is accepted and False otherwise\n",
    "        return True if accept_sample == 1 else False\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~  ALGORITHM FUNCTIONS ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~ 1.Percentage Random Batch Sampling ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    \n",
    "    def mini_batch_sampling(self):\n",
    "        accept_sample = random.randint(0, 1)\n",
    "        mini_start = (self.i // self.mini_batch_size)*self.mini_batch_size\n",
    "        mini_end = mini_start + (self.i % self.mini_batch_size) + 1\n",
    "\n",
    "        print(\"mini_start: \",mini_start,\"mini_end: \", mini_end) if self.debug_mode is True else None\n",
    "        print(\"Mini Batch: \",self.sel_arr[mini_start:mini_end]) if self.debug_mode is True else None\n",
    "\n",
    "        # MINI BATCH  --------------------------------------------------------------\n",
    "        # No. of mini batch and batch slots that must be filled to satisfy percentage criteria\n",
    "        mini_batch_count = np.count_nonzero(self.sel_arr[mini_start:mini_end])\n",
    "        if mini_batch_count >= self.mini_batch_slots_to_be_filled:\n",
    "            accept_sample = 0\n",
    "        \n",
    "        print(\"If Mini Batch Count: \",mini_batch_count,\" >= mini slots \",self.mini_batch_slots_to_be_filled,\" then 0\") if self.debug_mode is True else None\n",
    "            \n",
    "        # Lower bound for mini batch percentage criteria\n",
    "        if (self.i % self.mini_batch_size) >= (self.mini_batch_size - self.mini_batch_slots_to_be_filled) and mini_batch_count <self.mini_batch_slots_to_be_filled:\n",
    "            accept_sample = 1\n",
    "        \n",
    "        print(\"If Mini Batch iterator: \",self.i % self.mini_batch_size,\" >= rem mini slots \",self.mini_batch_size - self.mini_batch_slots_to_be_filled, \"and Mini Batch Count: \",mini_batch_count,\" < mini slots \",self.mini_batch_slots_to_be_filled,\" then 1\") if self.debug_mode is True else None\n",
    "\n",
    "        # BATCH ------------------------------------------------\n",
    "        ### BATCH SIZE INFORMATION HAS TO COME FROM CENTRAL NODE\n",
    "        start = (self.i // self.batch_size)*self.batch_size\n",
    "        end = start + (self.i % self.batch_size) + 1\n",
    "        batch_count = np.count_nonzero(self.sel_arr[start:end])\n",
    "        if batch_count >= self.batch_slots_to_be_filled:\n",
    "            accept_sample = 0\n",
    "        \n",
    "        print(\"start: \",start,\"end: \", end) if self.debug_mode is True else None\n",
    "        print(\"Batch: \",self.sel_arr[start:end]) if self.debug_mode is True else None\n",
    "        print(\"If Batch Count: \",batch_count,\" >= slots \",self.batch_slots_to_be_filled, \" then 0\") if self.debug_mode is True else None\n",
    "        # Lower bound for batch percentage criteria\n",
    "        print(\"If Batch iterator: \",self.i % self.batch_size,\" >= rem slots \",self.batch_size - self.batch_slots_to_be_filled, \"and Batch Count: \",batch_count,\" < slots \",self.batch_slots_to_be_filled, \" then 1\") if self.debug_mode is True else None\n",
    "\n",
    "        if (self.i % self.batch_size) >= (self.batch_size - self.batch_slots_to_be_filled) and batch_count < self.batch_slots_to_be_filled:\n",
    "            accept_sample = 1\n",
    "\n",
    "        return accept_sample\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 2.Epsilon Greedy Sampling ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "# https://arxiv.org/pdf/2104.02822.pdf   -- maybe try later\n",
    "\n",
    "    def scheduler_sampling(self,training_sample):\n",
    "        n = self.initial_sample_size # Set it at the top\n",
    "        \n",
    "        # Accept first n samples\n",
    "        if self.sample_counter < n:\n",
    "            accept_sample = 1   \n",
    "            \n",
    "        elif self.sample_counter >= n and self.sample_counter < 2*n:\n",
    "            accept_sample = self.region_compute(training_sample)\n",
    "\n",
    "        elif self.sample_counter >= 2*n and self.sample_counter < 3*n:\n",
    "            accept_sample =1\n",
    "\n",
    "        elif self.sample_counter >= 3*n:\n",
    "            accept_sample = self.region_compute(training_sample)\n",
    "        \n",
    "        else:\n",
    "            accept_sample = 0\n",
    "\n",
    "        return accept_sample\n",
    "    \n",
    "    def region_compute(self,sample):\n",
    "        retval = 0\n",
    "        smpl_lbl,smpl_dt= self.prepare_binary(sample)\n",
    "        r = self.region(test_input=smpl_dt) # distance function\n",
    "        if r == 1 or r == -1:  \n",
    "            # P3 or P1 REGION\n",
    "            # Test the label data with the prediction\n",
    "            for key, val in self.classes.items():\n",
    "                if val == sample['label'].values[0]:\n",
    "                    cls = key\n",
    "            print(\"cls: \",cls) if self.debug_mode is True else None\n",
    "            if cls == r:\n",
    "                # if correct it will reinforce the current hyperplane\n",
    "                # REINFORCE WITH PROBABILITY EPSILON\n",
    "                retval = self.epsilon_greedy(self.epsilon_out)\n",
    "            else:\n",
    "                # if incorrect now make the call to keep it or not -> it will change hyperplane\n",
    "                # CHANGE WITH PROBABILITY 1-EPSILON\n",
    "                retval = self.epsilon_greedy(1-self.epsilon_out)\n",
    "            \n",
    "        if r != -1 or r != 1:\n",
    "            # MUDDY PREDICTION --> most impact\n",
    "            # in the P2 region take this sample -> r is the distance from the hyperplane\n",
    "            retval = self.epsilon_greedy(self.epsilon_sv)\n",
    "        \n",
    "        return retval\n",
    "    \n",
    "    def epsilon_greedy(self,eps):\n",
    "        # Another type of sampling\n",
    "        p = np.random.randn()\n",
    "        if p < eps:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ TRAIN FUNCTION ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "    def train(self,traindata,trainlabel):\n",
    "        \n",
    "        #USAGE\n",
    "        # W, w = train(traindata, trainlabel)\n",
    "\n",
    "        # m: Number of feature vectors\n",
    "        # W and w: Weight vector and Bias value respectively\n",
    "        print(\"STARTING TRAINING. DATA SIZE    \",traindata.shape) if self.debug_mode is True else None\n",
    "        m = traindata.shape[1]\n",
    "        W = cp.Variable((m,1))\n",
    "        w = cp.Variable()\n",
    "        prob = self._hinge_loss_svm(traindata,trainlabel,W,w)\n",
    "        prob.solve()\n",
    "        # Solving the problem would give us the optimal values from W and w;\n",
    "        # which have to be returned, so that we can use them while testing\n",
    "        ## adding to class variable\n",
    "        self.w = W\n",
    "        self.b = w\n",
    "        print(\"============================TRAINED==========================\") if self.debug_mode is True else None\n",
    "    \n",
    "    def _hinge_loss_svm(self,traindata, trainlabel,W,w):\n",
    "        m =traindata.shape[1]\n",
    "        # Equation for the regularizer.\n",
    "        # It is the lambda*(norm2 of W)**2\n",
    "        # Here \"lambda\" is a non negative constant\n",
    "        lambd = cp.Parameter(nonneg=True)\n",
    "\n",
    "        ## Ideally we will have to try using different values fro \"lambda\"\n",
    "        ## For the sake of testing the code, we have set it to 0.01\n",
    "        ## Do we need to have a lambda?\n",
    "        lambd = 0.01 \n",
    "        reg_loss = cp.norm(W,p=2)**2\n",
    "        \n",
    "        #hinge loss\n",
    "        hinge_loss = cp.sum(cp.pos(1-cp.multiply(trainlabel,traindata @ W - w)))\n",
    "        \n",
    "        #Objective is to minimize reg_loss and hinge_loss\n",
    "        # objective_func = cp.Minimize(hinge_loss/m + lambd*reg_loss)\n",
    "        prob = cp.Problem(cp.Minimize(hinge_loss/m + lambd*reg_loss))\n",
    "        # Now framing the LP, along with the constraints\n",
    "        return prob\n",
    "    \n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ OTHER FUNCTIONS USED IN SAMPLE SELECTION AND TRAIN ~~~~~~~~~~~~~~~\n",
    "    \n",
    "    def prepare_binary(self,dataset):\n",
    "        #USAGE    \n",
    "        # Since we have to deal with a binary classifier to diffrentiate between digits 7 and 1, \n",
    "        # we choose only those examples.\n",
    "        # If asked to train a classifier on any other pair a, b (say),\n",
    "        # please pass the right arguments to the following function as follows:\n",
    "        # trainlabel, traindata, dataTargetDf = prepare_binary(a,b)\n",
    "\n",
    "\n",
    "        # We now assign +1 to one class and -1 to the other;\n",
    "        # Therefore +1 and -1 will be the new labels\n",
    "        class1 = self.classes[1]\n",
    "        class2 = self.classes[-1]\n",
    "\n",
    "        trainlabel = dataset.loc[(dataset['label']== class1)  | (dataset['label']== class2) ]['label']\n",
    "        trainlabel.loc[trainlabel == class1] = 1\n",
    "        trainlabel.loc[trainlabel == class2] = -1\n",
    "        trainlabel = trainlabel.to_numpy()\n",
    "    \n",
    "        #In order to match dimensions of \"traindata\" and \"trainlabel\", we convert trainlabel to two dimension array\n",
    "        # for hinge loss\n",
    "        trainlabel= np.reshape(trainlabel, (trainlabel.shape[0],1))   \n",
    "\n",
    "        # We now extract the features for the two classes\n",
    "        traindata = dataset.loc[(dataset['label']== class1)  | (dataset['label']== class2) ]\n",
    "        traindata = traindata.drop(labels = [\"label\"],axis = 1)\n",
    "        traindata = traindata.to_numpy()\n",
    "\n",
    "        return trainlabel, traindata\n",
    "    \n",
    "    def region(self,test_input,w=None,b=None):\n",
    "        if w is None:\n",
    "            w = self.w.value\n",
    "        if b is None:\n",
    "            b = self.b.value\n",
    "        r = self.dist(test_input,w,b)\n",
    "        if r < -1:\n",
    "            return -1\n",
    "        elif r > 1:\n",
    "            return 1\n",
    "        else:\n",
    "            return r\n",
    "        \n",
    "    def dist(self,test_input,w=None,b=None):\n",
    "        if w is None:\n",
    "            w = self.w.value\n",
    "        if b is None:\n",
    "            b = self.b.value\n",
    "        dist_val = test_input.dot(w) -  b\n",
    "        return dist_val.item()\n",
    "    \n",
    "    def store_w_b(self):\n",
    "        # Store the w and b values each time, classifier is trained\n",
    "        if self.w_hist is None:\n",
    "            self.w_hist = self.w.value\n",
    "            self.b_hist = np.reshape(np.array([self.b.value]),[-1,1])\n",
    "\n",
    "        else:\n",
    "            self.w_hist = np.hstack((self.w_hist,self.w.value))\n",
    "            self.b_hist = np.hstack((self.b_hist,np.reshape(np.array([self.b.value]),[-1,1])))\n",
    "\n",
    "        return None\n",
    "\n",
    "# ~~~~~~~~~~~~~~ TEST AND PLOT FUNCTIONS (USED SEPARATELY ie: not called in sample selection and train) ~~~~~~~~~~~\n",
    "\n",
    "    def test(self,dataset_test,w=None,b=None):\n",
    "        if w is None:\n",
    "            w = self.w.value\n",
    "        if b is None:\n",
    "            b = self.b.value\n",
    "        testlabel,testdata= self.prepare_binary(dataset_test)\n",
    "        res = []\n",
    "        performance = 0\n",
    "        for i in range(testdata.shape[0]):\n",
    "            result = self.f(testdata[i],w,b)\n",
    "            res.append(result)\n",
    "            \n",
    "            actual_class = self.classes.get(int(testlabel[i]))\n",
    "            ## assessing performance\n",
    "            if result == actual_class:\n",
    "                performance += 1 \n",
    "        performance /= testlabel.shape[0]\n",
    "        return res, performance\n",
    "\n",
    "    \n",
    "    def plot_classifier_performance_vs_number_of_samples(self, dataset_test, to_plot = True):\n",
    "        \n",
    "        r_hist = None\n",
    "        p_hist = None\n",
    "        \n",
    "        for it in range(0,self.w_hist.shape[1]):\n",
    "            res, performance = self.test(dataset_test,np.reshape(my_clf.w_hist[:,it],[-1,1]),np.reshape(my_clf.b_hist[:,it],[-1,1]))\n",
    "            if r_hist is None and p_hist is None:\n",
    "                r_hist,p_hist = res,performance\n",
    "            else:\n",
    "                r_hist = np.append(r_hist,res)\n",
    "                p_hist = np.append(p_hist,performance)\n",
    "        y = p_hist.tolist()\n",
    "        x = range(self.batch_size,self.batch_size*(self.sample_counter//self.batch_size+1),self.batch_size)\n",
    "        if to_plot == True:\n",
    "            plt.plot(x,y)\n",
    "        \n",
    "        return x,y\n",
    "\n",
    "    def f(self,test_input,w=None,b=None):\n",
    "        if w is None:\n",
    "            w = self.w.value\n",
    "        if b is None:\n",
    "            b = self.b.value\n",
    "        test_val =  self.region(test_input,w,b)\n",
    "        if test_val == -1 or test_val == 1:\n",
    "            test_val = test_val\n",
    "        else:\n",
    "            test_val = 0\n",
    "        estimated_class = self.classes.get(test_val)\n",
    "        return estimated_class\n",
    "    \n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~    \n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ UNUSED FUNCTIONS ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    \n",
    "    def reset_training_dataset(self):\n",
    "        self.yet_to_train_dataset = self.dataset_train\n",
    "        self.sampled_dataset = None\n",
    "        \n",
    "        self.i = 0 # Dataset Iterator \n",
    "        self.sel_arr = np.zeros(self.traindata.shape[0]) # Binary Array indicating whether a sample -\n",
    "                     # is selected or not in order of sample selection and not dataset index\n",
    "\n",
    "    def train_different_sample_sizes_and_store_performance(self,list_of_samples):\n",
    "        test_dataset = pd.read_csv('mnist/mnist_test.csv')\n",
    "        correctness = []\n",
    "        for percent_sampling in list_of_samples:\n",
    "            self.selection_and_train(select_samples_percent=percent_sampling)\n",
    "            res,performance = self.test(test_dataset)\n",
    "            correctness.append(performance)\n",
    "            \n",
    "        return correctness\n",
    "    \n",
    "    def target_df(self,traindata,trainlabel):\n",
    "        # Also creating a dataframe with these, so that we can randomize the order of the train data when needed without\n",
    "        # losing the mapping between feature vectors and the target labels\n",
    "        trainDf=pd.DataFrame(traindata)\n",
    "        targetDf=pd.DataFrame(trainlabel,columns=['target'])\n",
    "        \n",
    "        dataTargetDf = pd.concat([trainDf, targetDf[['target']]], axis = 1)\n",
    "        ##If randomizing the order, should we use the dataframe 'finalDf'?\n",
    "        return dataTargetDf\n",
    "\n",
    "    def subset(self,dataTargetDf, subsetfrac:float):\n",
    "        \n",
    "        # Usage: If 20% of the data is to be randomly selected\n",
    "        # subsetDf = subset(dataTargetDf, 0.2)\n",
    "        \n",
    "        return dataTargetDf.sample(frac = subsetfrac)\n",
    "    \n",
    "    def _normal_loss_svm(self,traindata,trainlabel, W,w):\n",
    "        #Constraint\n",
    "        # For every feature vector traindata[i] and its corresponding label trainlabel[i]:\n",
    "        # W^T*traindata[i] + w >= 1\n",
    "        const = [trainlabel[i]*(traindata[i]@ W + w) >= 1 for i in range(traindata.shape[0])]\n",
    "        ##Check the dimensions in the above constraint equation\n",
    "        \n",
    "        #Objective is to minimize reg_loss and hinge_loss\n",
    "        # objective_func = cp.Minimize(hinge_loss/m + lambd*reg_loss)\n",
    "        objective_func = cp.Minimize(0.5*cp.norm(W,p=2)**2)\n",
    "        prob = cp.Problem(objective_func,constraints=const)\n",
    "        \n",
    "        # Now framing the LP, along with the constraints\n",
    "        return prob\n",
    "    \n",
    "    def assess_classifier_performance(self,performance):\n",
    "        performance = np.asarray(performance)\n",
    "        correct = (np.count_nonzero(performance)/len(performance))*100\n",
    "        \n",
    "        return correct\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ END OF CLASS ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "273eb303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAsl0lEQVR4nO3deXxV1bn/8c9DAoFAGAJJGEOYJxXFgAIOIIr2WrW9tnVsrW2liNrx11vb29tfp/u7vdf2dlJE61Vvbx1qtd7S1haQQsGZgKCQgIY5BBLmOSHD8/tjb+wxnsABsnNyku/79crrnL322mc/iyHP2WvtvZa5OyIiIg21S3YAIiLSMilBiIhIXEoQIiISlxKEiIjEpQQhIiJxKUGIiEhcShDSKpjZ42b2g4g++xYzm3+C/VPMrCyKc4skkxKEpBQzW2xme80so7nO6e5PuPv0mBjczIY21/nD871tZu1iyn5gZo9HcK6zzGyeme0yMz0k1cYpQUjKMLMC4GLAgWub6ZzpzXGeBPQFbmyG89QAzwCfbYZzSQunBCGp5FPAa8DjwG0nqmhm/2Rm282s3Mw+F/ut38y6mdmvzGynmW02s28d/3ZuZp82s5fN7Cdmtgf4Tlj2Urh/SXiKVWZ2yMxuiDnnV82sMjzv7THlj5vZbDP7c3jMy2bW28x+Gl4NrTWz807S9v8AvttYwjKza81sjZntC6+yRp3k8+Jy93Xu/l/AmtM5XloXJQhJJZ8Cngh/rjSzvHiVzOwq4CvA5cBQ4NIGVX4BdAMGh/s+Bdwes/8CYAOQC/xr7IHufkn4dqy7d3H334TbvcPP7Efw7fsBM+sRc+gngG8BvYBq4FVgRbj9LPCfJ2n774ADwKfjtHc48BTwJSAHeAH4g5l1iFM3P0wi+Sc5n4gShKQGM7sIGAg84+7LgfXAzY1U/wTwmLuvcfcjwHdjPicNuAH4hrsfdPdNwI+BT8YcX+7uv3D3Wnc/mmCINcD33L3G3V8ADgEjYvY/7+7L3b0KeB6ocvdfuXsd8BvgZFcQDvwL8O044y83AH9y9wXuXgP8COgETPrAh7hvcffu7r4lwXZJG6YEIaniNmC+u+8Kt5+k8W6mvsDWmO3Y972ADsDmmLLNBN/849VP1G53r43ZPgJ0idmuiHl/NM52bN24wsSzBZjRYFdfYtrj7vUEbeiHyBloKQNwIo0ys04EVwVpZrYjLM4AupvZWHdf1eCQ7UD/mO0BMe93EXzbHwgUh2X5wLaYOi357p1vAU8TJMjjyoGzj2+YmRG0eRsiZ0BXEJIKPgLUAaOBc8OfUcBSgvGDhp4BbjezUWaWCXz7+I6wS+cZ4F/NLMvMBhKMV/z6FOKpIBi/aHbuvhh4m/dfPT0DXG1m08ysPfBVgnGOV0718y3QkeAqCzPr2Jy3FEvLogQhqeA2gjGFLe6+4/gPcD9wS8M7e9z9z8DPgUVAKcGAMAS/NAHuAQ4TDES/RPBt/NFTiOc7wH+Hg72fOM02nYlvAdnHN9x9HXArweD7LuAa4Bp3PwYQ3jl1cfg+P9xubJB6IEGX1/G7mI4C6yJphbR4pgWDpLULb/lcDWQ0GCcQkRPQFYS0Smb2UTPrEN5q+u/AH5QcRE6NEoS0Vp8HdhLcDlsH3JnccERST6RdTOEDSz8D0oBH3P2HDfZ3IxgczCe4o+pH7v5YuG8TcJDgP3etuxdGFqiIiHxAZAkifCDpHeAKoAxYBtzk7sUxdb4JdHP3r5tZDsFgWG93PxYmiMKY+95FRKQZRfkcxASg1N03AJjZ08B1/P3ecwjuN88K79vuAuwBTrufuFevXl5QUHDaAYuItDXLly/f5e458fZFmSD68f4nUssI5riJdT8wl+BBnyzghvApUAiSx/xwyuGH3P3heCcxsxmET5bm5+dTVFTUdC0QEWnlzGxzY/uiHKS2OGUN+7OuBFYSTBVwLnC/mXUN901293HAh4C7zOwS4nD3h9290N0Lc3LiJkERETkNUSaIMt4/xUF/giuFWLcDv/NAKbARGAng7uXhayXB5GYTIoxVREQaiDJBLAOGmdmgcNrhGwm6k2JtAaYBhFM3jwA2mFlnM8sKyzsD0wkedBIRkWYS2RiEu9ea2d3APILbXB919zVmNjPcPwf4PvC4mb1N0CX1dXffZWaDgeeDsWvSgSfd/S9RxSoiIh/UqqbaKCwsdA1Si4gkzsyWN/acmZ6kFhGRuJQgREQkLi0YJCKSgo4eq2NdxUGKyw+w/2gNd04Z0uTnUIIQEWnhdh6spmT7AYq3H6C4PHjdsPMQ9eEQcm5WBjMvHUx4Y0+TUYIQEWkh6uqdzbsPvy8RFJcfoPJg9Xt1+nXvxKg+XfmHs/swuk9XxvTtSv8enZo8OYAShIhIUsR2ERVv309x+QHW7jjIkWN1AKS3M4bmduGiYb0Y3acro/t2ZXSfrnTP7NBsMSpBiIhE7GRdRFkZ6Yzq25VPFA54LxEMy+tCRnpaUuNWghARaSItrYvoTClBiIichlToIjpTShAiIieRql1EZ0oJQkQk1Nq6iM6UEoSItEltoYvoTClBiEibsPNgNUWb9vDGpj0s27SH4vIDrb6L6EwpQYhIq+PubN59hGVhMli2aS8bdx0GICO9Hefld2fWlKGc1a9bq+4iOlNKECKS8urqnZLtBygKk8GyTXveGzfo1qk94wt6cOP4AYwflM1ZfbvRIV3zlCZCCUJEUk5VTR1vle1n2aY9vLFxDys27+VgdS0Afbt1ZOKQnowvyGbCoGyG5nShXTtdHZwOJQgRafH2H61hxea9wfjBxj28VbafY3X1AAzL7cI15/ZlQkE24wdl0697pyRH23ooQYhIi7Njf9V74wdvbNzDuoqDuAd3Fp3VrxufnlzA+IJsCgf2oEfntnNXUXNTghCRpHJ3Nuw6zLKNf7/DaOueowBkdkhjXH4PPnRWH8YP6sG5A7qT2UG/tpqL/qRFpFnV1tVTvP0Ab2wMkkHRpr3sPnwMgJ6dO1BY0IPbJhYwYVA2o/t0JT1NA8rJogQhIpE6eqyON7fuZdnG4O6iFVv2vvcw2oDsTlw6Iue98YPBvTrrdtMWRAlCRJrU3sPHKNq8973xg9Xb9lNb75jBiLwsPnZ+f8YXZDO+IJve3TomO1w5ASUIETkj2/Yd/fv4wcY9vFt5CIAOae04p3837rhkMBMKshk3sAfdOrVPcrRyKpQgRCRh9fVO6c5D740fLNu4h/L9VUAwXcW4gT34yHn9GF+QzTn9u9GxfdueqiLVRZogzOwq4GdAGvCIu/+wwf5uwK+B/DCWH7n7Y4kcKyLN41B1LUvf2cmCkgoWr9vJnnBAOScrgwkF2cwo6MH4QdmM7N2VND2Q1qpEliDMLA14ALgCKAOWmdlcdy+OqXYXUOzu15hZDrDOzJ4A6hI4VkQism3fURaWVPBiSSWvrd/Nsbp6unVqz9QROUwe2ovxBdkM7JmpAeVWLsoriAlAqbtvADCzp4HrgNhf8g5kWfCvrAuwB6gFLkjgWBFpIvX1ztvb9rOwpIIFJZWUbD8AwKBenblt0kAuH5XH+QN76JbTNibKBNEP2BqzXUbwiz/W/cBcoBzIAm5w93ozS+RYETkDVTV1vFy6ixdLKllYUkHlwWraGRQOzOYbHxrJ5aPzGJLTJdlhShJFmSDiXXt6g+0rgZXAZcAQYIGZLU3w2OAkZjOAGQD5+fmnG6tIm1B5sIpFaytZUFzJS6U7qaqpp0tGOpcM78Xlo/KYMiKXbE1dIaEoE0QZMCBmuz/BlUKs24EfursDpWa2ERiZ4LEAuPvDwMMAhYWFcZOISFvl7qyrOMiLxcF4wsqt+4Bg2cwbCgcwbVQeFwzObvML40h8USaIZcAwMxsEbANuBG5uUGcLMA1YamZ5wAhgA7AvgWNFJI5jtfW8vnE3C0sqWVBcwbZ9wbxGYwd056tXDOfy0XmM7J2lAWY5qcgShLvXmtndwDyCW1Ufdfc1ZjYz3D8H+D7wuJm9TdCt9HV33wUQ79ioYhVJdfuOHGPRukpeLKlkybqdHKyuJSO9HRcP68Xdlw1l2shccrvqqWU5NRb07rQOhYWFXlRUlOwwRJrFhp2HgquEkgqWb95LXb2Tk5XBtJG5XD4qj8lDe9Gpg7qO5MTMbLm7F8bbpyepRVJEbV09K7bs48WSCl4sqWDDzmCN5ZG9s5g1ZQjTRuVxTr9uWj1NmowShEgLdrCqhiXv7GJhSQV/XVfJviM1tE8zLhzck9smFjBtVC79e2QmO0xppZQgRFqYsr1HWFhSyYslFby2YTc1dU73zPZcNiKXy0fncfGwXmR11KR3Ej0lCJEkq6933tq2P7wVtYK1Ow4CMDinM5+ZPIhpo/IYl99dTzFLs1OCEEmCo8eOP8VcwcK1lew8/hRzQTb//A+jmDYql8F6ilmSTAlCpJlUHqhi4dpgWoul7+6iujZ4ivnSETlcPiqXKcNz6aGnmKUFUYIQiYi7827lIeav2cGC4gpWle0HoH+PTtw0IZ/LR+UxYVA2HdLVdSQtkxKESBOqq3fe3LKX+cUVzF+zg027jwDBU8xfu3IE00blMiJPTzFLalCCEDlDVTV1vLp+N/OLd7CguJJdh6ppn2ZMHNKLOy4ZzBWj8vQUs6QkJQiR03CgqoZFayuZX1zB4rWVHD5WR5eMdKaMyGH6mN5MGZFDV92KKilOCUIkQRUHqlhQXMG8NTveez6hV5cMrj23H9PH5DFpSE/NiiqtihKEyAms33mIeWt2MH9NxXtTZRf0zOQzkwcxfUwe5w3ooaktpNVSghCJUV/vrCrb994g8/pwvqNz+nfja1eOYProPIbmdtEgs7QJShDS5h2rree1DccHmSuoOFBNertwvqNJBVw+Ko++3TslO0yRZqcEIW3SoepaFq+rZP6aChatreRgdS2d2qeFg8x5XDYij26ZGmSWtk0JQtqMnQerebEk6Dp6uXQ3x+rqye7cgQ+d3Zsrx/Rm8tBedGyvQWaR45QgpFXbtOsw84uDQeblW/biDgOyO/GpiQOZPqY35w/sQZoGmUXiUoKQVsXdWb3tAPOLdzBvzQ7eqTgEwJi+XfnStOFMH6P1mEUSpQQhKa+mrp5lG/cwL5zzqHx/Fe0MJgzK5tsfHs30MXlaVEfkNChBSEo6cqyWJe/sZP6aYLrs/Udr6Ni+HZcMy+Er00dw2chcsjUzqsgZUYKQlLH7UDUL1wZ3Hi19dyfVtfV0z2zP5aPymD4mj0uG5dCpgwaZRZqKEoS0aFv3HGF+OL1F0aY91Dv06x5Ml33lmN6ML+ihldZEIqIEIS3SX1bv4GcL36Vk+wEARvbO4u7LhjF9dB5j+nbVILNIM1CCkBblWG09/++FEh5/ZRMje2fxratHccXoPAb27Jzs0ETanEgThJldBfwMSAMecfcfNtj/NeCWmFhGATnuvsfMNgEHgTqg1t0Lo4xVkm/rniPc/dSbrNq6j89MHsS9Hxqp1dZEkiiyBGFmacADwBVAGbDMzOa6e/HxOu5+H3BfWP8a4MvuvifmY6a6+66oYpSWY0FxBV99ZiUOzLl1HFed1SfZIYm0eVFeQUwASt19A4CZPQ1cBxQ3Uv8m4KkI45EWqKaunh/NW8dDSzZwVr+uPHDzOHUnibQQUSaIfsDWmO0y4IJ4Fc0sE7gKuDum2IH5ZubAQ+7+cFSBSnJs33+Uu598k+Wb93Lrhfl86+rRmgtJpAWJMkHEu83EG6l7DfByg+6lye5ebma5wAIzW+vuSz5wErMZwAyA/Pz8M41ZmsnidZV85ZlVVNfU8fObzuPasX2THZKINBDlCGAZMCBmuz9Q3kjdG2nQveTu5eFrJfA8QZfVB7j7w+5e6O6FOTk5Zxy0RKs27FK6/fFl5GZlMPeei5QcRFqoKK8glgHDzGwQsI0gCdzcsJKZdQMuBW6NKesMtHP3g+H76cD3IoxVmkHlgSq+8PSbvLZhDzcUDuA7147Rk88iLVhkCcLda83sbmAewW2uj7r7GjObGe6fE1b9KDDf3Q/HHJ4HPB8+DJUOPOnuf4kqVoneK6W7+MLTKzlcXcuPPz6W68/vn+yQROQkzL2xYYHUU1hY6EVFRckOQ2LU1zv3Lyrlpy++w+CcLsy+ZRzD87KSHZaIhMxseWPPmelJaonM7kPVfOk3K1n67i4+el4/fvCRs+icoX9yIqlC/1slEm9s3MM9T61g75EafviPZ3PD+AGaP0kkxShBSJOqr3ceWrKBH81fx4AenXh01njG9O2W7LBE5DQoQUiT2Xv4GF/97Sr+uraSq8/uww+vP5usju2THZaInCYlCGkSK7bs5Z4n36TyYBXfu24Mn7xwoLqURFKcEoScEXfn0Zc38W8vlNC7W0eeu3MS5/TvnuywRKQJKEHIadt/tIZ/enYV89ZUcMXoPH70sbF0y1SXkkhroQQhp2X1tv3MemIF5fuO8q2rR/HZiwapS0mklVGCkFPi7vz69S18/w/F9OzSgd98fiLnD+yR7LBEJAJKEJKwQ9W13PvcW/zxre1MGZHDf37iXLI7d0h2WCISESUISUjJ9gPc9cQKNu0+zNeuHMGdlw6hXTt1KYm0ZkoQckLuzjNFW/n279fQrVN7nrzjQi4c3DPZYYlIM1CCkEYdOVbLt/53Nb9bsY2LhvbiJzecS05WRrLDEpFmogQhcZVWHuTOX6+gdOchvnT5MO65bBhp6lISaVOUIOQDnn+zjG/+bjWdM9L4n89cwEXDeiU7JBFJAiUIeU9VTR3f/cMannpjKxMGZfOLm84jr2vHZIclIkly0gRhZh8GXnD3+maIR5Jkw85D3PXkm5RsP8CsKUP4yhXDSU+LcslyEWnpErmCuBH4mZk9Bzzm7iURxyTN7I9vlXPvc2+TnmY89unxTB2Zm+yQRKQFOGmCcPdbzawrcBPwmJk58BjwlLsfjDpAiU51bR3/+qcSfvXqZsbld+f+m8fRt3unZIclIi1EQn0I7n4AeA54GugDfBRYYWb3RBibRGjrniN87MFX+dWrm7nj4kH85vMTlRxE5H0SGYO4BvgMMAT4H2CCu1eaWSZQAvwi2hClqc1fs4Ov/nYVBjz8yfOZPqZ3skMSkRYokTGIjwM/cfclsYXufsTMPhNNWBKFmrp6/v3Pa3nkpY2c078bD9w8jgHZmckOS0RaqEQSxP8Fth/fMLNOQJ67b3L3hZFFJk1q276j3P3kCt7cso/bJg7km1ePIiM9LdlhiUgLlkiC+C0wKWa7LiwbH0lE0uQWra3ky8+spLbOeeDmcVx9Tp9khyQiKSCRBJHu7seOb7j7MTPTHM8poLaunh8veIcHF69nVJ+uzL5lHIN6dU52WCKSIhK5i2mnmV17fMPMrgN2JfLhZnaVma0zs1IzuzfO/q+Z2crwZ7WZ1ZlZdiLHyolVHKji5kde58HF67lpQj7Pz5qk5CAipySRK4iZwBNmdj9gwFbgUyc7yMzSgAeAK4AyYJmZzXX34uN13P0+4L6w/jXAl919TyLHSuNeencXX3z6TY4cq+MnN4zlo+f1T3ZIIpKCEnlQbj1woZl1AewUHo6bAJS6+wYAM3sauA5o7Jf8TcBTp3msEKzd8NMX3+Xnf32XoTldeHrGOIblZSU7LBFJUQlN1mdmVwNjgI7HF6Z39++d5LB+BFcbx5UBFzTy+ZnAVcDdp3HsDGAGQH5+/klCat3+8NZ2frbwXf7xvH784KNnkdlBczGKyOk76RiEmc0BbgDuIehi+jgwMIHPjrd4gDdS9xrgZXffc6rHuvvD7l7o7oU5OTkJhNU6uTuzF5UyLLcLP/r4WCUHETljiQxST3L3TwF73f27wERgQALHlTWo1x8ob6Tujfy9e+lUjxXgr2srWbvjIHdO0VrRItI0EkkQVeHrETPrC9QAgxI4bhkwzMwGhbfF3gjMbVjJzLoBlwK/P9VjJeDu3L+olP49OnHN2L7JDkdEWolE+iH+YGbdCe42WkHQ1fPLkx3k7rVmdjcwD0gDHnX3NWY2M9w/J6z6UWC+ux8+2bGJN6tteW3DHt7cso/vf+Qs2msNBxFpIube2LAAmFk74EJ3fyXczgA6uvv+ZorvlBQWFnpRUVGyw2h2n/yv1ynZfpCXvj6Vju01fYaIJM7Mlrt7Ybx9J/y6Ga4i9+OY7eqWmhzaqlVb97H03V3ccfEgJQcRaVKJ9EfMN7Pr7fj9rdKizF5cSteO6dxyYSI3lomIJC6RMYivAJ2BWjOrIrgF1d29a6SRyUm9W3GQeWsq+MK0YXTJ0G2tItK0EnmSWo/itlAPLl5PZoc0bp9UkOxQRKQVSmRFuUvilTdcQEia19Y9R/j9qnJun1RAj86aXFdEml4i/RJfi3nfkWCepOXAZZFEJAl5aMl60sz43MWDkx2KiLRSiXQxXRO7bWYDgP+ILCI5qcoDVTxTVMb15/end7eOyQ5HRFqp03mqqgw4q6kDkcT910sbqa2rZ+alunoQkegkMgbxC/4+UV474FxgVYQxyQnsO3KMX7+2mWvG9mVgTy0AJCLRSWQMIvbR5FrgKXd/OaJ45CT++5XNHD5Wx51ThiQ7FBFp5RJJEM8CVe5eB8FKcWaW6e5Hog1NGjpcXctjr2zk8lF5jOytx1BEJFqJjEEsBDrFbHcCXowmHDmRp97Ywr4jNcyaqqsHEYleIgmio7sfOr4Rvs+MLiSJp7q2jl8u3cCkIT0Zl98j2eGISBuQSII4bGbjjm+Y2fnA0ehCknh+t2IbFQequWvq0GSHIiJtRCJjEF8Cfmtmx1d060OwBKk0k9q6eub8bT1j+3dj0pCeyQ5HRNqIRB6UW2ZmI4ERBBP1rXX3msgjk/f86e3tbN59hG9+8nw0qa6INJeTdjGZ2V1AZ3df7e5vA13MbFb0oQlAfb0ze9F6huV24YpReckOR0TakETGIO5w933HN9x9L3BHZBHJ+/x1bSXrKg4ya+oQ2rXT1YOINJ9EEkS72MWCzCwN0PShzcDduX9RKf17dOKac/omOxwRaWMSSRDzgGfMbJqZXQY8Bfw52rAE4NUNu1m5dR8zLx1CetrpTJslInL6ErmL6evADOBOgkHqNwnuZJKIzV60npysDD52fv9khyIibdBJv5a6ez3wGrABKASmASURx9Xmrdy6j5dKd3HHxYPo2D4t2eGISBvU6BWEmQ0HbgRuAnYDvwFw96nNE1rbNntRKd06tefmCwYmOxQRaaNOdAWxluBq4Rp3v8jdfwHUNU9Ybds7FQeZX1zBpycV0CUjkV5AEZGmd6IEcT2wA1hkZr80s2kEYxAJM7OrzGydmZWa2b2N1JliZivNbI2Z/S2mfJOZvR3uK4p3bGv14OL1ZHZI49OTCpIdioi0YY1+PXX354Hnzawz8BHgy0CemT0IPO/u80/0weHtsA8AVxCsQrfMzOa6e3FMne7AbOAqd99iZrkNPmaqu+869Walri27jzB3VTmfmVxAj866m1hEkieRQerD7v6Eu38Y6A+sBOJeDTQwASh19w3ufgx4GriuQZ2bgd+5+5bwXJWnEnxr9NCS9aSZ8bmLtZyoiCTXKd1c7+573P0hd78sger9gK0x22VhWazhQA8zW2xmy83sU7GnA+aH5TMaO4mZzTCzIjMr2rlzZ6JNaZEqD1Tx26IyPlbYn7yuHZMdjoi0cVGOgMYbr/AG2+nA+QSD4Z2AV83sNXd/B5js7uVht9MCM1vr7ks+8IHuDwMPAxQWFjb8/JTyyEsbqa2vZ+YlWhBIRJIvysdzy4ABMdv9gfI4df4SdmPtApYAYwHcvTx8rQSeJ+iyarX2HTnGr1/bzLVj+5LfU+sxiUjyRZkglgHDzGyQmXUgeKZiboM6vwcuNrN0M8sELgBKzKyzmWUBhIPk04HVEcaadI+/sokjx+q4c4oWBBKRliGyLiZ3rzWzuwnmckoDHnX3NWY2M9w/x91LzOwvwFtAPfCIu682s8EEd1Adj/FJd/9LVLEm26HqWh57eRNXjM5jRO+sZIcjIgJEOwaBu78AvNCgbE6D7fuA+xqUbSDsamoLnnp9C/uP1jBrisYeRKTl0BShSVZdW8cvl25g0pCenJffI9nhiIi8RwkiyZ5bvo3Kg9XcNVVjDyLSsihBJFFtXT1z/raesQO6M2lIz2SHIyLyPkoQSfSnt7ezZc8R7poyhJhF+0REWgQliCSpr3dmL1rP8LwuXD4qL9nhiIh8gBJEkixcW8m6ioPMmjKUdu109SAiLY8SRBK4O/cvKmVAdic+fI5WbxWRlkkJIgleXb+bVVv3MfPSIaSn6a9ARFom/XZKggcWl5KblcH14/onOxQRkUYpQTSzN7fs5eXS3dxx8WA6tk9LdjgiIo1Sgmhmsxevp1un9tx8QX6yQxEROSEliGa0bsdBFhRXcPvkAjpnRDoNlojIGVOCaEYPLi4ls0Man55UkOxQREROSgmimWzZfYS5q8q59cKBdM/skOxwREROSgmimcxZsp70du343EWDkh2KiEhClCCaQcWBKp4tKuPjhf3J7dox2eGIiCRECaIZPLJ0A3XufP4SLQgkIqlDCSJiew8f44nXt3Dt2L7k98xMdjgiIglTgojY469s4sixOu7UcqIikmKUICJ0qLqWx1/ZxPTReQzPy0p2OCIip0QJIkJPvr6Z/UdrmKXlREUkBSlBRKSqpo5fLt3I5KE9OXdA92SHIyJyypQgIvLs8jJ2Hqzmrim6ehCR1KQEEYHaunoeWrKecwd0Z+KQnskOR0TktESaIMzsKjNbZ2alZnZvI3WmmNlKM1tjZn87lWNbqj++tZ2te45y19ShmGk5URFJTZFNKWpmacADwBVAGbDMzOa6e3FMne7AbOAqd99iZrmJHttS1dc7sxeXMiIvi2kjc5MdjojIaYvyCmICUOruG9z9GPA0cF2DOjcDv3P3LQDuXnkKx7ZIL5ZU8E7FIWZNHUK7drp6EJHUFWWC6AdsjdkuC8tiDQd6mNliM1tuZp86hWMBMLMZZlZkZkU7d+5sotBPj7vzwOL15GdncvXZfZIai4jImYoyQcT7+uwNttOB84GrgSuBfzGz4QkeGxS6P+zuhe5emJOTcybxnrFX1u9m1dZ9zLx0COlpGv8XkdQW5bJmZcCAmO3+QHmcOrvc/TBw2MyWAGMTPLbFeWBRKblZGVx/ftyLHRGRlBLl19xlwDAzG2RmHYAbgbkN6vweuNjM0s0sE7gAKEnw2BZlxZa9vLJ+NzMuGUxGelqywxEROWORXUG4e62Z3Q3MA9KAR919jZnNDPfPcfcSM/sL8BZQDzzi7qsB4h0bVaxNYfai9XTPbM9NE/KTHYqISJOIsosJd38BeKFB2ZwG2/cB9yVybEu1dscBXiyp4MuXD6dzRqR/pCIizUYjqU3gwcXr6dwhjdsmDUx2KCIiTUYJ4gxt3n2YP6wq59YLB9I9s0OywxERaTJKEGdozt82kJ7Wjs9eNCjZoYiINCkliDOwY38Vzy0v4xOF/cnt2jHZ4YiINCkliDPwyNIN1Lnz+Uu0nKiItD5KEKdp7+FjPPH6Fq4b25cB2ZnJDkdEpMkpQZymx17ZxNGaOmZO0dWDiLROShCn4VB1LY+/vJHpo/MYnpeV7HBERCKhBHEannhtMweqapk1VcuJikjrpQRxiqpq6vjl0o1cNLQX5w7onuxwREQiowRxin67vIxdh6qZNVVjDyLSuilBnIKaunoe+tt6zsvvzsTBPZMdjohIpJQgTsEfVpVTtvcod00ZipmWExWR1k0JIkH19c7sxesZ2TuLy0bmJjscEZHIKUEkaH5xBaWVh7hzyhDatdPVg4i0fkoQCXB3HlxcysCemVx9dp9khyMi0iyUIBLwculuVpXtZ+alQ0hP0x+ZiLQN+m2XgAcWlZLXNYN/HNcv2aGIiDQbJYiTWL55L69u2M0dFw8mIz0t2eGIiDQbJYiTeHBxKT0y23PThPxkhyIi0qyUIE6gZPsBXiyp5PbJg+ickZ7scEREmpUSxAk8uHg9nTukcdvEgmSHIiLS7JQgGrFp12H++FY5t04cSLfM9skOR0Sk2SlBNOKhJetJT2vHZy8alOxQRESSItIEYWZXmdk6Mys1s3vj7J9iZvvNbGX48+2YfZvM7O2wvCjKOBvasb+KZ5eXcUPhAHKzOjbnqUVEWozIRl7NLA14ALgCKAOWmdlcdy9uUHWpu3+4kY+Z6u67ooqxMb9cuoF6hxmXDG7uU4uItBhRXkFMAErdfYO7HwOeBq6L8HxNYs/hYzz5+hauG9uXAdmZyQ5HRCRpokwQ/YCtMdtlYVlDE81slZn92czGxJQ7MN/MlpvZjMZOYmYzzKzIzIp27tx5xkE//vJGjtbUcecULQgkIm1blDf3x5vy1BtsrwAGuvshM/sH4H+BYeG+ye5ebma5wAIzW+vuSz7wge4PAw8DFBYWNvz8U3KwqobHX9nElWPyGJaXdSYfJSKS8qK8gigDBsRs9wfKYyu4+wF3PxS+fwFob2a9wu3y8LUSeJ6gyypST7y+hQNVtcyaMjTqU4mItHhRJohlwDAzG2RmHYAbgbmxFcyst4VLs5nZhDCe3WbW2cyywvLOwHRgdYSxUlVTxyNLN3LxsF6MHdA9ylOJiKSEyLqY3L3WzO4G5gFpwKPuvsbMZob75wAfA+40s1rgKHCju7uZ5QHPh7kjHXjS3f8SVawAvy3ayq5D1cyacl6UpxERSRnmfkbd9i1KYWGhFxWd+iMTNXX1TLlvMXldM3juzklab1pE2gwzW+7uhfH26UlqYO7KcrbtO8pdU4cqOYiIhNp8gqivd2YvLmVk7ywuG5mb7HBERFqMNj+H9ZGaOsYXZHPxsBxdPYiIxGjzCaJLRjo/vP6cZIchItLitPkuJhERiU8JQkRE4lKCEBGRuJQgREQkLiUIERGJSwlCRETiUoIQEZG4lCBERCSuVjVZn5ntBDaf5uG9gGZf/zoiraUtraUdoLa0RK2lHXBmbRno7jnxdrSqBHEmzKyosRkNU01raUtraQeoLS1Ra2kHRNcWdTGJiEhcShAiIhKXEsTfPZzsAJpQa2lLa2kHqC0tUWtpB0TUFo1BiIhIXLqCEBGRuJQgREQkrjaRIMzsUTOrNLPVMWXZZrbAzN4NX3vE7PuGmZWa2TozuzI5UcdnZgPMbJGZlZjZGjP7YlieUu0xs45m9oaZrQrb8d2wPKXaEcvM0szsTTP7Y7idkm0xs01m9raZrTSzorAsVdvS3cyeNbO14f+ZianWFjMbEf5dHP85YGZfapZ2uHur/wEuAcYBq2PK/gO4N3x/L/Dv4fvRwCogAxgErAfSkt2GmLj7AOPC91nAO2HMKdUewIAu4fv2wOvAhanWjgZt+grwJPDHFP83tgno1aAsVdvy38DnwvcdgO6p2pYwxjRgBzCwOdqR9AY34x9sQYMEsQ7oE77vA6wL338D+EZMvXnAxGTHf4J2/R64IpXbA2QCK4ALUrUdQH9gIXBZTIJI1bbESxAp1xagK7CR8GacVG5LTEzTgZebqx1tooupEXnuvh0gfM0Ny/sBW2PqlYVlLY6ZFQDnEXz7Trn2hF0yK4FKYIG7p2Q7Qj8F/gmojylL1bY4MN/MlpvZjLAsFdsyGNgJPBZ2/T1iZp1JzbYcdyPwVPg+8na05QTRGItT1uLuBTazLsBzwJfc/cCJqsYpaxHtcfc6dz+X4Nv3BDM76wTVW2w7zOzDQKW7L0/0kDhlLaItocnuPg74EHCXmV1ygrotuS3pBF3LD7r7ecBhgq6YxrTktmBmHYBrgd+erGqcstNqR1tOEBVm1gcgfK0My8uAATH1+gPlzRzbCZlZe4Lk8IS7/y4sTtn2uPs+YDFwFanZjsnAtWa2CXgauMzMfk1qtgV3Lw9fK4HngQmkZlvKgLLwyhTgWYKEkYptgSBhr3D3inA78na05QQxF7gtfH8bQV/+8fIbzSzDzAYBw4A3khBfXGZmwH8BJe7+nzG7Uqo9ZpZjZt3D952Ay4G1pFg7ANz9G+7e390LCLoA/urut5KCbTGzzmaWdfw9QZ/3alKwLe6+A9hqZiPComlAMSnYltBN/L17CZqjHckedGmmgZ2ngO1ADUF2/SzQk2BQ8d3wNTum/j8TjPyvAz6U7PgbtOUigsvFt4CV4c8/pFp7gHOAN8N2rAa+HZanVDvitGsKfx+kTrm2EPTbrwp/1gD/nKptCWM7FygK/539L9AjFdtCcCPHbqBbTFnk7dBUGyIiEldb7mISEZETUIIQEZG4lCBERCQuJQgREYlLCUJEROJSgpBWx8zczH4cs/1/zOw7EZznKTN7y8y+3KB8hJktDmfeLDGzSFcuM7Mpx2eQFWlK6ckOQCQC1cA/mtm/ufuuKE5gZr2BSe4+MM7unwM/cfffh3XPjiIGkajpCkJao1qCNXq/3HCHmQ00s4XhN/+FZpZ/og+yYN2Kx8L1Ed40s6nhrvlAbniVcHGDw/oQPJAJgLu/HX5WgZktNbMV4c+ksHyKmf3NzJ4xs3fM7IdmdosF62W8bWZDwnqPm9mc8DPeCeeAahhvZwvWP1kWxntdWD4m/LyVYduHJfqHKW2XEoS0Vg8At5hZtwbl9wO/cvdzgCcIvu2fyF0A7n42wVQH/21mHQkmTVvv7ue6+9IGx/wE+KuZ/dnMvnx8ShGCuXKu8GAivBsanHss8EXgbOCTwHB3nwA8AtwTU68AuBS4GpgTxhLrnwmm+hgPTAXuC6fMmAn8zIPJEQuJSWAijVGCkFbJgxlufwV8ocGuiQSL+gD8D8HUJSdyUVgPd18LbAaGn+TcjwGjCGbdnAK8ZmYZBAsj/dLM3g73jY45bJm7b3f3aoIpEuaH5W8TJIXjnnH3end/F9gAjGxw+unAveE06ouBjkA+8CrwTTP7OjDQ3Y+epN0iGoOQVu2nBAsRPXaCOiebaybe1Mkn5cGMqI8Cj1qw1O1ZwDVABcHVQjugKuaQ6pj39THb9bz//2nDeBtuG3C9u69rUF5iZq8TXHnMM7PPuftfT61V0tboCkJaLXffAzxDMDnjca8QzLgKcAvw0kk+ZklYDzMbTvBtvOEv3/cxs6vCKdmPD2b3BLYB3YDt7l5P0I2UdirtCX3czNqF4xKD48QyD7gnnPUXMzsvfB0MbHD3nxPM9nnOaZxb2hglCGntfgz0itn+AnC7mb1F8Ev6iwBmNtPMZsY5fjaQFnYL/Qb4dNgNdCLTgdVmtorgF/bXPJh6ejZwm5m9RtBNdfg02rMO+BvwZ2Cmu1c12P99gq6st8Irl++H5TeEMa0k6Jb61WmcW9oYzeYqkiLM7HGCqcSfTXYs0jboCkJEROLSFYSIiMSlKwgREYlLCUJEROJSghARkbiUIEREJC4lCBERiev/A+jeogYclToJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (7,) (11,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/7q/nxjkhqk91hqcpldmvtwmtzqc0000gn/T/ipykernel_2170/1241806865.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mavg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mavg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0mavg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mavg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (7,) (11,) "
     ]
    }
   ],
   "source": [
    "import numpy as np  # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "mnist_train = pd.read_csv(\"train.csv\")\n",
    "mnist_test = pd.read_csv(\"mnist_test.csv\")\n",
    "#Take copies of the master dataframes\n",
    "\n",
    "train = mnist_train.copy()\n",
    "tester = mnist_test.copy()\n",
    "tester = tester.loc[tester['label'].isin([4,9])]\n",
    "\n",
    "train_class_1 = train.loc[train['label'] == 4]\n",
    "train_class_2 = train.loc[train['label'] == 9]\n",
    "train = train.loc[train['label'].isin([4,9])]\n",
    "train_rdm = train.sample(frac = 0.5)\n",
    "test_rdm = train.sample(frac = 0.2)\n",
    "\n",
    "\n",
    "# Testing the Algorithm performance by averaging from 10 classifiers\n",
    "avg = None\n",
    "num = 5\n",
    "# Outer Loop for algorithm\n",
    "for i in range(1,3):\n",
    "    # Inner Loop for averaging accuracy performance\n",
    "    for j in range (num):\n",
    "        my_clf = MyClassifier_25(train,4,9,i)\n",
    "        x,y = my_clf.plot_classifier_performance_vs_number_of_samples(tester,False)\n",
    "        if avg is None:\n",
    "            avg = y\n",
    "        else:\n",
    "            avg = np.add(np.array(avg),np.array(y)).tolist()\n",
    "    avg = (np.array(avg) / num).tolist()\n",
    "    plt.plot(x,avg)\n",
    "    plt.title(\"Algorithm No.: %i\"%i)\n",
    "    plt.xlabel(\"No. of Samples\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d2b601",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_clf = MyClassifier_25(train,4,9)\n",
    "res, performance = my_clf.test(test_rdm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3e34dfcc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x,y = my_clf.plot_classifier_performance_vs_number_of_samples(tester)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
